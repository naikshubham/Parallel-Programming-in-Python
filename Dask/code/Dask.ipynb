{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How big is my DataFrame?\n",
    "`df.info()` , `df.memory_usage()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy transformations\n",
    "- Many NumPy transformations, while fast, use one or more temporary arrays. Therefore, those transformations require more storage than the original array required.\n",
    "- The function memory_footprint() has been provided to return the total amount of memory (in megabytes or MB) currently in use by our program. This function uses the psutil and os modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import psutil, os\n",
    "import matplotlib.pyplot as plt\n",
    "# from glob import glob\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "def memory_footprint():\n",
    "    '''Returns memory (in MB) being used by Python process'''\n",
    "    mem = psutil.Process(os.getpid()).memory_info().rss\n",
    "    return (mem / 1024 **2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "N = (1024 **2) //8 # number of floats that fill 1 MB\n",
    "celsius = np.random.randn(50 * N) # Random array filling 50MB\n",
    "\n",
    "# Print the size in MB of the celsius array\n",
    "print(celsius.nbytes / 1024**2)\n",
    "\n",
    "# Call memory_footprint(): before\n",
    "before = memory_footprint()\n",
    "\n",
    "# Convert celsius by multiplying by 9/5 and adding 32: fahrenheit\n",
    "fahrenheit = celsius * 9/5 + 32\n",
    "\n",
    "# Call memory_footprint(): after\n",
    "after = memory_footprint()\n",
    "\n",
    "# Print the difference between after and before\n",
    "print(after - before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing percentage of delayed flights\n",
    "- build a function to compute the percentage of delayed flights given a DataFrame of flight information. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function with single input called df: pct_delayed\n",
    "def pct_delayed(df):\n",
    "    # Compute number of delayed flights: n_delayed\n",
    "    n_delayed = (df['DEP_DELAY'] > 0).sum()\n",
    "    # Return percentage of delayed flights\n",
    "    return n_delayed  * 100 / len(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating & plotting delayed flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the generator: dataframes\n",
    "filenames = glob.glob('../data/flightdelays/*.csv')\n",
    "dataframes = (pd.read_csv(file) for file in filenames)\n",
    "\n",
    "# Create the list comprehension: monthly_delayed\n",
    "monthly_delayed = [pct_delayed(df) for df in dataframes]\n",
    "\n",
    "# Create the plot\n",
    "x = range(1,6)\n",
    "plt.plot(x, monthly_delayed, marker='o', linewidth=0)\n",
    "plt.ylabel('% Delayed')\n",
    "plt.xlabel('Month - 2016')\n",
    "plt.xlim((1,6))\n",
    "plt.ylim((0,100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a pipeline with delayed\n",
    "- If we use `dask.delayed`, we don't need to use generators; the dask scheduler will manage memory usage.\n",
    "- **Task** : define three decorated functions to complete the pipeline: a function to total the number of flights, a function to count the number of delayed flights, and a function to aggregate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shubham\\Anaconda3\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "from dask import delayed\n",
    "import os \n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define count_flights\n",
    "@delayed\n",
    "def count_flights(df):\n",
    "    return len(df)\n",
    "\n",
    "# Define count_delayed\n",
    "@delayed\n",
    "def count_delayed(df):\n",
    "    return (df['DEP_DELAY']>0).sum()\n",
    "\n",
    "# Define pct_delayed\n",
    "@delayed\n",
    "def pct_delayed(n_delayed, n_flights):\n",
    "    return 100 * sum(n_delayed) / sum(n_flights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These functions constitute the pieces of the pipeline for our flight-delay analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing pipelined results\n",
    "- Now that the dask.delayed functions are defined, we can use them to construct the pipeline of delayed tasks.\n",
    "-  loop over the file names, store the temporary information in lists, and aggregate the final result.\n",
    "- The distinction here is that we are working with `dask.delayed` functions and objects, not real, computed values. The computation will only be executed when we call `.compute()` on the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/flightdelays\\\\flightdelays-2016-1.csv',\n",
       " '../data/flightdelays\\\\flightdelays-2016-2.csv',\n",
       " '../data/flightdelays\\\\flightdelays-2016-3.csv',\n",
       " '../data/flightdelays\\\\flightdelays-2016-4.csv',\n",
       " '../data/flightdelays\\\\flightdelays-2016-5.csv']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = glob.glob('../data/flightdelays/*.csv')\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.406252934201824\n"
     ]
    }
   ],
   "source": [
    "n_delayed = []\n",
    "n_flights = []\n",
    "# Loop over the provided filenames list and call read_one: df\n",
    "for file in filenames:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Append to n_delayed and n_flights\n",
    "    n_delayed.append(count_delayed(df))\n",
    "    n_flights.append(count_flights(df))\n",
    "\n",
    "# Call pct_delayed with n_delayed and n_flights: result\n",
    "result = pct_delayed(n_delayed, n_flights)\n",
    "\n",
    "# Print the output of result.compute()\n",
    "print(result.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice that no reading and no computation was done until the last line (result.compute()). In all the preceding lines, the functions called returned dask.delayed objects that deferred execution until the invocation of compute()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtracting & broadcasting\n",
    "- The one-dimensional array load_2001 holds the total electricity load for the state of Texas sampled every 15 minutes for the entire year 2001 (35040 samples in total). The one-dimensional array load_recent holds the corresponding data sampled for each of the years 2013 through 2015 (i.e., 105120 samples consisting of the samples from 2013, 2014, & 2015 in sequence). None of these years are leap years, so each year has 365 days. Observe also that there are 96 intervals of duration 15 minutes in each day.\n",
    "- compute the differences of the samples in the years 2013 to 2015 each from the corresponding samples of 2001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset name: <KeysViewHDF5 ['load']>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35040,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "hf = h5py.File('../data/Texas/texas.2001.hdf5', 'r')\n",
    "print('dataset name:', hf.keys())\n",
    "load_2001 = np.array(hf[\"load\"][:]) #dataset_name is same as hdf5 object name \n",
    "load_2001.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset name: <KeysViewHDF5 ['load']>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(105120,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf = h5py.File('../data/Texas/texas.2013.hdf5', 'r')\n",
    "hf_14 = h5py.File('../data/Texas/texas.2014.hdf5', 'r')\n",
    "hf_15 = h5py.File('../data/Texas/texas.2015.hdf5', 'r')\n",
    "print('dataset name:', hf.keys())\n",
    "load_2013 = np.array(hf[\"load\"][:]) #dataset_name is same as hdf5 object name \n",
    "load_2014 = np.array(hf_14[\"load\"][:])\n",
    "load_2015 = np.array(hf_15[\"load\"][:])\n",
    "load_recent = np.hstack([load_2013,load_2014,load_2015])\n",
    "load_recent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1153.309    22.598   -17.925]\n"
     ]
    }
   ],
   "source": [
    "# Reshape load_recent to three dimensions: load_recent_3d\n",
    "load_recent_3d = load_recent.reshape((3,365,96))\n",
    "\n",
    "# Reshape load_2001 to three dimensions: load_2001_3d\n",
    "load_2001_3d = load_2001.reshape((1,365,96))\n",
    "\n",
    "# Subtract the load in 2001 from the load in 2013 - 2015: diff_3d\n",
    "diff_3d = load_recent_3d - load_2001_3d\n",
    "\n",
    "# Print the difference each year on March 2 at noon\n",
    "print(diff_3d[:, 61, 48])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing aggregations\n",
    "- compute summary statistics by aggregating NumPy arrays across various dimensions (in this case, giving trends in electricity usage).\n",
    "- `load_recent_3d` contains the electricity load (in kWh) sampled every 15 minutes from the start of 2013 to the end of 2015. The possible index values of the three-dimensional array correspond to year (from 0 to 2), day (from 0 to 364), and 15-minute interval (from 0 to 95); remember, NumPy arrays are indexed from zero. Thus, load_recent_3d[0,1,2] is the electricity load consumed on January 2nd, 2013 from 00:30:00 AM to 00:45:00 AM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5240.84666194825\n",
      "[6335.42  6336.159 6344.077]\n",
      "470184.43899999995\n"
     ]
    }
   ],
   "source": [
    "# Print mean value of load_recent_3d\n",
    "print(load_recent_3d.mean())\n",
    "\n",
    "# Print maximum of load_recent_3d across 2nd & 3rd dimensions\n",
    "print(load_recent_3d.max(axis=(1,2)))\n",
    "\n",
    "# Compute sum along last dimension of load_recent_3d: daily_consumption\n",
    "daily_consumption = load_recent_3d.sum(axis=-1)\n",
    "\n",
    "# Print mean of 62nd row of daily_consumption\n",
    "print(daily_consumption[:,61].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting a large DataFrame\n",
    "\n",
    "### Building a pipeline of delayed tasks\n",
    "- filter the DataFrame for the 'East Asia & Pacific' region and measurements of the percent population exposed to toxic air pollution. The output of this effort is a delayed Dask DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shubham\\Anaconda3\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "C:\\Users\\Shubham\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas.compat' has no attribute 'string_types'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-13e45d383433>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Filter the DataFrame using toxins & region: filtered\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mfiltered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoxins\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mregion\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0miindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0mcindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\indexing.py\u001b[0m in \u001b[0;36m_loc\u001b[1;34m(self, iindexer, cindexer)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;34m\"\"\" Helper function for the .loc accessor \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loc_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mknown_divisions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\indexing.py\u001b[0m in \u001b[0;36m_loc_series\u001b[1;34m(self, iindexer, cindexer)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mmeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_meta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         return self.obj.map_partitions(methods.loc, iindexer, cindexer,\n\u001b[1;32m--> 134\u001b[1;33m                                        token='loc-series', meta=meta)\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_loc_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py\u001b[0m in \u001b[0;36mmap_partitions\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mddf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_partitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_divisions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# doctest: +SKIP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \"\"\"\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmap_partitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minsert_meta_param_description\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py\u001b[0m in \u001b[0;36mmap_partitions\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3728\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmulti\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_maybe_align_partitions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3729\u001b[1;33m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_from_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3730\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_align_partitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3731\u001b[0m     \u001b[0mdfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py\u001b[0m in \u001b[0;36m_maybe_from_pandas\u001b[1;34m(dfs)\u001b[0m\n\u001b[0;32m   3475\u001b[0m     dfs = [from_pandas(df, 1)\n\u001b[0;32m   3476\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mis_series_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_dataframe_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_dask_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3477\u001b[1;33m            else df for df in dfs]\n\u001b[0m\u001b[0;32m   3478\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdfs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3475\u001b[0m     dfs = [from_pandas(df, 1)\n\u001b[0;32m   3476\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mis_series_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_dataframe_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_dask_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3477\u001b[1;33m            else df for df in dfs]\n\u001b[0m\u001b[0;32m   3478\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdfs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py\u001b[0m in \u001b[0;36mis_series_like\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mis_series_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[1;34m\"\"\" Looks like a Pandas Series \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'dtype'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'groupby'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'head'\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py\u001b[0m in \u001b[0;36m__dir__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2563\u001b[0m         \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2564\u001b[0m         \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2565\u001b[1;33m         o.update(c for c in self.columns if\n\u001b[0m\u001b[0;32m   2566\u001b[0m                  (isinstance(c, pd.compat.string_types) and\n\u001b[0;32m   2567\u001b[0m                   pd.compat.isidentifier(c)))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2564\u001b[0m         \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2565\u001b[0m         o.update(c for c in self.columns if\n\u001b[1;32m-> 2566\u001b[1;33m                  (isinstance(c, pd.compat.string_types) and\n\u001b[0m\u001b[0;32m   2567\u001b[0m                   pd.compat.isidentifier(c)))\n\u001b[0;32m   2568\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas.compat' has no attribute 'string_types'"
     ]
    }
   ],
   "source": [
    "# Read from 'WDI.csv': df\n",
    "import dask.dataframe as dd\n",
    "\n",
    "df = dd.read_csv('../data/WDI/WDI.csv')\n",
    "\n",
    "# Boolean series where 'Indicator Code' is 'EN.ATM.PM25.MC.ZS': toxins\n",
    "toxins = df['Indicator Code'] == 'EN.ATM.PM25.MC.ZS'\n",
    "# Boolean series where 'Region' is 'East Asia & Pacific': region\n",
    "region = df['Region'] == 'East Asia & Pacific'\n",
    "\n",
    "# Filter the DataFrame using toxins & region: filtered\n",
    "filtered = df.loc[toxins & region]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping & aggregating by year\n",
    "-  plot the average percent of the population exposed to air pollution in the East Asia & Pacific region from 2010 to 2015.\n",
    "- use .groupby() to collect all of the individual country values by the 'Year' column and aggregate with the mean() function. Then call .compute() to perform the computation in parallel, and finally plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
